# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor
from catboost import CatBoostRegressor

# Load data
# Replace 'data_path' with your actual path to the data
data = pd.read_csv('~/data/train_data.csv')
print(data.head())

# Data Cleaning
# Drop unnecessary columns
columns_to_drop = ['ID', 'ADM0_NAME']
data = data.drop(columns=columns_to_drop)

# Check for missing values
print("Missing values:\n", data.isnull().sum())

# Fill missing values or drop rows/columns with missing values if necessary
#data = data.fillna(data.mean())

# Feature and Target Variable
X = data.drop(columns=['target'])
y = data['target']

# Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("Done Normalization")

# Feature Engineering: Expand features (e.g., elevation)
# Example: Expand elevation to elevation^2 and elevation^3
X_expanded = np.hstack([X_scaled, np.square(X_scaled[:, [X.columns.get_loc('Elevation')]]),
                         np.power(X_scaled[:, [X.columns.get_loc('Elevation')]], 3)])

print("Done Scaling")

# Apply PCA for feature extraction
pca = PCA(n_components=10)  # You may need to adjust the number of components
X_pca = pca.fit_transform(X_expanded)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)

print("Done Splitting")

# Define models
models = {
    'Bagging': BaggingRegressor(),
    'RandomForest': RandomForestRegressor(),
   # 'GradientBoosting': GradientBoostingRegressor(),
   # 'CatBoost': CatBoostRegressor(verbose=0),
}

# Function to evaluate model
def evaluate_model(model, X_train, X_test, y_train, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    print("Model Eval")
    return rmse

# Cross-validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for model_name, model in models.items():
    fold_rmse = []
    for train_index, val_index in kf.split(X_pca):
        X_train_fold, X_val_fold = X_pca[train_index], X_pca[val_index]
        y_train_fold, y_val_fold = y[train_index], y[val_index]
        rmse = evaluate_model(model, X_train_fold, X_val_fold, y_train_fold, y_val_fold)
        fold_rmse.append(rmse)
    print(f'{model_name} - Mean RMSE: {np.mean(fold_rmse)}')

# Select the best model (you can refine this selection process)
best_model_name = 'RandomForest'  # Assuming RandomForest performed best
best_model = models[best_model_name]

# Retrain on the whole training set
best_model.fit(X_pca, y)

# Predictions on test data (assuming 'test_data_path' is provided)
test_data = pd.read_csv('~/data/test_data.csv')
test_data_cleaned = test_data.drop(columns=columns_to_drop)
test_data_scaled = scaler.transform(test_data_cleaned)
test_data_expanded = np.hstack([test_data_scaled, np.square(test_data_scaled[:, [X.columns.get_loc('Elevation')]]),
                                np.power(test_data_scaled[:, [X.columns.get_loc('Elevation')]], 3)])
test_data_pca = pca.transform(test_data_expanded)
test_predictions = best_model.predict(test_data_pca)

# Format and save predictions
submission = pd.DataFrame({'ID': test_data['ID'], 'target': test_predictions})
submission.to_csv('~/data/submission.csv', index=False)

print("Submission file created successfully.")
